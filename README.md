# üèóÔ∏è Robinson AI Systems - MCP Servers

**Complete 4-Server Architecture for Augment Code**
**Save 70-85% on credits while adding 956+ tools**

**Website:** https://www.robinsonaisystems.com
**Date:** 2025-10-21
**Status:** ‚úÖ **PRODUCTION READY**

---

## üéØ **The Problem We Solved**

**Before Robinson AI Systems:**
- ‚ùå Augment Code has NO tools (can only explain, not DO)
- ‚ùå Costs $45/month + overages ($0.10/1000 credits)
- ‚ùå User was 43% over limit (296K/208K credits/month)
- ‚ùå Stops and waits for confirmation constantly
- ‚ùå No access to GitHub, Vercel, Neon, Stripe, etc.

**After Robinson AI Systems:**
- ‚úÖ 966+ tools across 5 MCP servers
- ‚úÖ 70-85% credit savings
- ‚úÖ Autonomous workflows (no stopping!)
- ‚úÖ FREE local LLMs for heavy work
- ‚úÖ Plan ‚Üí Patch ‚Üí PR workflows
- ‚úÖ 10x faster planning (5-10s vs 60+s)
- ‚úÖ Web crawling & semantic search (RAD Crawler)

---

## üèóÔ∏è **The 5-Server Architecture**

### **1. Architect Agent MCP** üß†
**Purpose:** Strategic planning, critique, and architectural insights
**Model:** Local Ollama (FREE)
**Tools:** 12 planning & analysis tools
**Performance:** 5-10s for simple plans, 15-30s for complex

**What it does:**
- Creates detailed WorkPlans from intent
- Reviews architecture and suggests improvements
- Generates Architecture Decision Records (ADRs)
- Identifies risks and technical debt
- Security & performance reviews

**Key Features:**
- ‚úÖ **Design-only** - Never writes to disk
- ‚úÖ **Auto-start Ollama** - No manual intervention
- ‚úÖ **Smart routing** - Fast model for 90% of plans
- ‚úÖ **HEAD caching** - No re-indexing on subsequent calls
- ‚úÖ **10x faster** - 5-10s vs 60+s before optimizations

---

### **2. Autonomous Agent MCP** ü§ñ
**Purpose:** Code generation using FREE local LLMs
**Model:** Local Ollama (qwen2.5-coder:32b, codellama:34b, deepseek-coder:33b)
**Tools:** 8 code generation tools

**What it does:**
- Generates code from specifications
- Refactors existing code
- Adds tests automatically
- Fixes bugs and errors
- Optimizes performance

**Key Features:**
- ‚úÖ **Auto-start Ollama** - Saves Augment credits
- ‚úÖ **Smart model selection** - Fast for simple, best for complex
- ‚úÖ **FREE** - Local LLM, zero credits
- ‚úÖ **Quality** - Uses best coding models (33B-34B parameters)

---

### **3. Credit Optimizer MCP** üí∞
**Purpose:** Workflows, templates, patches, and autonomous execution
**Tools:** 24 optimization tools

**What it does:**
- **Tool Discovery** - Find tools instantly (0 credits!)
- **Autonomous Workflows** - Execute multi-step plans without stopping
- **Template Scaffolding** - Generate features/components (0 AI credits!)
- **Caching** - Avoid re-doing work
- **PR Creation** - `open_pr_with_changes` tool (Plan ‚Üí Patch ‚Üí PR!)

**Key Features:**
- ‚úÖ **70-85% credit savings**
- ‚úÖ **No stopping** - Autonomous execution
- ‚úÖ **Templates** - 0 AI credits for scaffolding
- ‚úÖ **PR automation** - Create PRs with file changes

---

### **4. Robinson's Toolkit MCP** üõ†Ô∏è
**Purpose:** 912+ integration tools (GitHub, Vercel, Neon, Stripe, etc.)
**Tools:** 912 tools across 12 integrations

**Integrations:**
1. **GitHub** (199 tools) - Repos, PRs, issues, actions, releases
2. **Vercel** (150 tools) - Deployments, domains, env vars, analytics
3. **Neon** (145 tools) - Postgres databases, branches, queries
4. **Stripe** (100 tools) - Payments, subscriptions, customers
5. **Supabase** (80 tools) - Auth, database, storage, functions
6. **Resend** (60 tools) - Email sending and management
7. **Twilio** (70 tools) - SMS, voice, messaging
8. **Cloudflare** (50 tools) - DNS, CDN, workers, R2
9. **Redis** (40 tools) - Caching, pub/sub, streams
10. **OpenAI** (30 tools) - Completions, embeddings, models
11. **Playwright** (78 tools) - Browser automation, testing
12. **Context7** (3 tools) - Documentation retrieval

**Key Features:**
- ‚úÖ **Lazy loading** - Only loads integrations when needed
- ‚úÖ **Unified interface** - One server, all tools
- ‚úÖ **Production ready** - Battle-tested integrations

---

### **5. RAD Crawler MCP** üï∑Ô∏è
**Purpose:** Retrieval-Augmented Development - Web crawling & semantic search
**Model:** Local Ollama (FREE embeddings & classification)
**Tools:** 10 crawling & search tools

**What it does:**
- Crawls web documentation with governance (robots.txt, rate limits)
- Ingests code repositories for semantic search
- Hybrid search (FTS + pgvector semantic)
- Smart deduplication and chunking
- Local AI for embeddings (zero cloud credits!)

**Key Features:**
- ‚úÖ **Search-first** - Check index before crawling
- ‚úÖ **Governed crawling** - Allow/deny lists, budgets, robots.txt
- ‚úÖ **Semantic search** - pgvector for concept-based retrieval
- ‚úÖ **Job queue** - Async processing with progress tracking
- ‚úÖ **Zero cloud credits** - All AI runs on local Ollama
- ‚úÖ **Neon storage** - Scalable Postgres with pgvector

**Use Cases:**
- Index documentation you frequently reference
- Search your codebase semantically
- Build knowledge base for your agents
- Auto-gather context for planning

---

## üí∞ **Credit Savings Breakdown**

| Task | Without Robinson AI | With Robinson AI | Savings |
|------|---------------------|------------------|---------|
| **Find tools** | 500 credits | 0 credits | 100% |
| **Plan work** | 2,000 credits | 0 credits (local LLM) | 100% |
| **Generate code** | 5,000 credits | 0 credits (local LLM) | 100% |
| **Execute workflow** | 10,000 credits | 500 credits | 95% |
| **Create PR** | 1,500 credits | 100 credits | 93% |
| **Deploy** | 2,000 credits | 100 credits | 95% |

**Average savings: 70-85%**

---

## üöÄ **Getting Started**

### **1. Install All 4 Servers**

```bash
# Clone the repository
git clone https://github.com/robinsonai/robinsonai-mcp-servers.git
cd robinsonai-mcp-servers

# Install dependencies
npm install --legacy-peer-deps

# Build all servers
npm run build

# Link all servers globally
cd packages/architect-mcp && npm link
cd ../autonomous-agent-mcp && npm link
cd ../credit-optimizer-mcp && npm link
cd ../robinsons-toolkit-mcp && npm link
cd ../rad-crawler-mcp && npm link
```

### **2. Configure Augment Code**

Add to VS Code settings (`settings.json`). On Windows with Augment, prefer absolute executables (don‚Äôt rely on PATH) and keep stdout clean.

Option A: Absolute .cmd shims (requires `npm link` for each package)

```json
{
  "augment.mcpServers": {
    "architect-agent": {
      "command": "C:\\nvm4w\\nodejs\\architect-mcp.cmd",
      "args": [],
      "env": {
        "OLLAMA_BASE_URL": "http://localhost:11434",
        "ARCHITECT_MODEL": "qwen2.5:3b"
      }
    },
    "autonomous-agent": {
      "command": "C:\\nvm4w\\nodejs\\autonomous-agent-mcp.cmd",
      "args": [],
      "env": { "OLLAMA_BASE_URL": "http://localhost:11434" }
    },
    "credit-optimizer": {
      "command": "C:\\nvm4w\\nodejs\\credit-optimizer-mcp.cmd",
      "args": [],
      "env": { "CREDIT_OPTIMIZER_SKIP_INDEX": "1" }
    },
    "robinsons-toolkit": {
      "command": "C:\\nvm4w\\nodejs\\robinsons-toolkit-mcp.cmd",
      "args": [],
      "env": {
        "GITHUB_TOKEN": "your-token",
        "VERCEL_TOKEN": "your-token",
        "NEON_API_KEY": "your-key"
      }
    }
  }
}
```

Option B: Explicit node + dist entry (no global link required)

```json
{
  "augment.mcpServers": {
    "architect-agent": {
      "command": "C:\\Program Files\\nodejs\\node.exe",
      "args": ["C:\\Users\\chris\\Git Local\\robinsonai-mcp-servers\\packages\\architect-mcp\\dist\\index.js"],
      "env": {
        "OLLAMA_BASE_URL": "http://localhost:11434",
        "ARCHITECT_MODEL": "qwen2.5:3b"
      }
    }
  }
}
```

Option C (fallback): npx via absolute shim (may be slower, can emit stdout noise)

```json
{
  "augment.mcpServers": {
    "architect-agent": {
      "command": "C:\\nvm4w\\nodejs\\npx.cmd",
      "args": ["-y", "@robinsonai/architect-mcp"],
      "env": { "OLLAMA_BASE_URL": "http://localhost:11434" }
    }
  }
}
```

Tip: Use `node tools/generate-augment-mcp-import.mjs` to generate Windows-safe import JSONs (including an optional secrets file). 

### **3. Install Ollama Models**

```bash
ollama pull qwen2.5:3b           # Fast planning (2GB)
ollama pull qwen2.5-coder:32b    # Fast coding (19GB)
ollama pull codellama:34b        # Balanced coding (19GB)
ollama pull deepseek-coder:33b   # Best quality (19GB)
```

### **4. Restart VS Code**

All 4 servers will auto-start Ollama when needed!

---

## üìä **System Requirements**

- **Disk:** 60 GB (for Ollama models)
- **RAM:** 16 GB minimum, 32 GB recommended
- **CPU:** Modern multi-core processor
- **OS:** Windows, macOS, or Linux
- **Node.js:** 18+ required

---

## üéØ **Use Cases**

1. **Feature Development** - Plan ‚Üí Code ‚Üí Test ‚Üí PR
2. **Bug Fixes** - Analyze ‚Üí Fix ‚Üí Test ‚Üí Deploy
3. **Refactoring** - Plan ‚Üí Refactor ‚Üí Test ‚Üí PR
4. **Deployments** - Build ‚Üí Deploy ‚Üí Monitor
5. **Database Migrations** - Plan ‚Üí Migrate ‚Üí Verify
6. **Email Campaigns** - Template ‚Üí Send ‚Üí Track
7. **Testing** - Generate ‚Üí Run ‚Üí Report

---

## üì¶ **Individual Packages**

### [@robinsonai/architect-mcp](./packages/architect-mcp)
Strategic planning and architectural insights using local LLMs. 12 tools for planning, review, and analysis.

### [@robinsonai/autonomous-agent-mcp](./packages/autonomous-agent-mcp)
Code generation via local LLMs. 8 tools for generating, refactoring, and optimizing code.

### [@robinsonai/credit-optimizer-mcp](./packages/credit-optimizer-mcp)
Workflow optimization and autonomous execution. 24 tools for discovery, templates, caching, and PR creation.

### [@robinsonai/robinsons-toolkit-mcp](./packages/robinsons-toolkit-mcp)
912+ integration tools across 12 services (GitHub, Vercel, Neon, Stripe, etc.)

### [@robinsonai/vercel-mcp](./packages/vercel-mcp)
Full-featured Vercel API integration with 150+ tools for deployments, domains, environment variables, teams, and more.

### [@robinsonai/neon-mcp](./packages/neon-mcp)
Enhanced Neon database management with 145 tools for workflows, migrations, performance monitoring, and branch management.

### [@robinsonai/github-mcp](./packages/github-mcp)
Advanced GitHub automation with 199 tools for PR workflows, issue management, Actions integration, and repository analytics.

---

## üéì Training System

**Want to train your own custom models?**

This repo includes a complete automated LoRA training system that learns from your codebase!

üìö **[See `.training/` folder for complete documentation](./.training/)**

**Quick Start:**
```bash
# Check if ready to train
npm run check-training

# Open Colab for one-click training
npm run train-colab -- --role=coder
```

**Features:**
- ‚úÖ Automated data collection from agent runs
- ‚úÖ One-click training on free Google Colab GPU
- ‚úÖ +20-30% better performance after training
- ‚úÖ Model learns your codebase patterns
- ‚úÖ Works with Python 3.14 (no local setup needed)

**Read more:** [`.training/AUTOMATED_TRAINING_GUIDE.md`](./.training/AUTOMATED_TRAINING_GUIDE.md)

---

## üìÑ License

MIT ¬© Robinson AI Systems

## ü§ù Contributing

These MCP servers are built and maintained by Robinson AI Systems for internal use and community benefit.

